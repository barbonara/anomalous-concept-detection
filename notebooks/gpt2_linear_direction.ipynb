{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to use contrasting pairs of animal/non-animal related sentences to identify an \"animal direction\" in any of the layers in the residual stream of the last tokens of the sentences in GPT2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/anaconda3/envs/acd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def get_last_token_activations(sentences, model, tokenizer, device='cpu'):\n",
    "    # Get activations from last token across specified layers\n",
    "\n",
    "    activations = {}\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output[0].detach()\n",
    "        return hook\n",
    "\n",
    "    hooks = [layer.register_forward_hook(get_activation(f'Layer_{i}')) for i, layer in enumerate(model.transformer.h)]\n",
    "\n",
    "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with t.no_grad():\n",
    "        model(**inputs)\n",
    "    last_token_indices = (inputs['attention_mask'].sum(dim=1) - 1).tolist()\n",
    "\n",
    "    # Clean up hooks after use\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    return {key: val[:, last_token_indices, :] for key, val in activations.items()}\n",
    "\n",
    "def compute_animal_directions(animal_sentences, non_animal_sentences, model, layer_names, tokenizer, device='cpu'):\n",
    "    \"\"\"\n",
    "    Computes the direction vector (difference in means of activations) for animal vs. non-animal sentences\n",
    "    across specified layers in a given model.\n",
    "\n",
    "    Parameters:\n",
    "    - animal_sentences (list of str): Sentences classified as 'animal'.\n",
    "    - non_animal_sentences (list of str): Sentences classified as 'non-animal'.\n",
    "    - model (torch.nn.Module): Model to compute activations from.\n",
    "    - tokenizer (Tokenizer): Tokenizer that is compatible with the model.\n",
    "    - device (str): Device to perform computations on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with layer names as keys and direction vectors as values.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # activations = {}\n",
    "\n",
    "    # def get_activation(name):\n",
    "    #     def hook(model, input, output):\n",
    "    #         activations[name] = output[0].detach()\n",
    "    #     return hook\n",
    "\n",
    "    # hooks = [layer.register_forward_hook(get_activation(f'Layer_{i}')) for i, layer in enumerate(model.transformer.h)]\n",
    "\n",
    "    # def get_last_token_activations(sentences):\n",
    "    #     inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    #     with t.no_grad():\n",
    "    #         model(**inputs)\n",
    "    #     last_token_indices = (inputs['attention_mask'].sum(dim=1) - 1).tolist()\n",
    "    #     return {key: val[:, last_token_indices, :] for key, val in activations.items()}\n",
    "\n",
    "    animal_activations = get_last_token_activations(animal_sentences, model, tokenizer)\n",
    "\n",
    "    non_animal_activations = get_last_token_activations(non_animal_sentences, model, tokenizer)\n",
    "\n",
    "\n",
    "    animal_directions = {}\n",
    "\n",
    "    for layer_name in layer_names:\n",
    "        animal_layer_activations = animal_activations[layer_name].cpu().numpy()\n",
    "        non_animal_layer_activations = non_animal_activations[layer_name].cpu().numpy()\n",
    "\n",
    "        print(animal_layer_activations.shape)\n",
    "        animal_directions[layer_name] = np.mean(animal_layer_activations, axis=0) - np.mean(non_animal_layer_activations, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return animal_directions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Label           Sentence\n",
      "0  Animal       I like cats.\n",
      "1  Animal       I like dogs.\n",
      "2  Animal  I like elephants.\n",
      "3  Animal     I like tigers.\n",
      "4  Animal      I like birds.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file to verify it\n",
    "df_sentences = pd.read_csv('../datasets/ilikecats.csv')\n",
    "\n",
    "# Display the first few entries\n",
    "print(df_sentences.head())\n",
    "\n",
    "# Filter the DataFrame for rows where the Label column is 'Animal'\n",
    "animal_sentences = df_sentences[df_sentences['Label'] == 'Animal']['Sentence'].tolist()\n",
    "non_animal_sentences = df_sentences[df_sentences['Label'] == 'Non-Animal']['Sentence'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model #huggingface-cli login\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "# Set the EOS token as the padding token if it's not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers = 12\n",
      "Number of tokens = 10\n"
     ]
    }
   ],
   "source": [
    "# Print max number of layers and max number of tokens\n",
    "print(f\"Number of layers = {len(model.transformer.h)}\")\n",
    "max_tokens = tokenizer(df_sentences['Sentence'].tolist(), return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].shape[-1]\n",
    "print(f\"Number of tokens = {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 80, 768)\n"
     ]
    }
   ],
   "source": [
    "# Compute animal direction for each layer\n",
    "layer_names = [f'Layer_{i}' for i in range(6,7)] # Max is range(len(model.transformer.h)\n",
    "\n",
    "\n",
    "# Shorten samples, create train-test split, Shuffle sentences\n",
    "\n",
    "num_examples = 100\n",
    "animal_sentences_short = animal_sentences[0:num_examples]\n",
    "non_animal_sentences_short = non_animal_sentences[0:num_examples]\n",
    "\n",
    "train_test_split = 0.8\n",
    "\n",
    "train_animal_sentences = animal_sentences_short[0:int(num_examples*0.8)]\n",
    "test_animal_sentences = animal_sentences_short[int(num_examples*0.8):]\n",
    "\n",
    "train_non_animal_sentences = non_animal_sentences_short[0:int(num_examples*0.8)]\n",
    "test_non_animal_sentences = non_animal_sentences_short[int(num_examples*0.8):]\n",
    "\n",
    "\n",
    "random.shuffle(animal_sentences_short)\n",
    "random.shuffle(non_animal_sentences_short)\n",
    "\n",
    "activation_directions = compute_animal_directions(train_animal_sentences, train_non_animal_sentences, model, layer_names, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_activations(activations, detector_direction):\n",
    "    \"\"\"\n",
    "    Project activation vectors onto the detector direction.\n",
    "    \n",
    "    Parameters:\n",
    "    - activations (numpy.ndarray): Activation vectors to project.\n",
    "    - detector_direction (numpy.ndarray): The detector direction vector.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: Scalar values of the projection of each activation onto the detector direction.\n",
    "    \"\"\"\n",
    "\n",
    "    print(activations.shape, detector_direction.shape)\n",
    "    # Project each activation onto the normalized detector direction\n",
    "    projection = np.dot(activations, detector_direction)\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "test_data = test_animal_sentences + test_non_animal_sentences\n",
    "labels = [1]*len(test_animal_sentences) + [0]*len(test_non_animal_sentences)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activations = get_last_token_activations(test_data, model, tokenizer, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 768)\n"
     ]
    }
   ],
   "source": [
    "print(activation_directions['Layer_6'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 40, 768]) (80, 768)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (40,40,768) and (80,768) not aligned: 768 (dim 2) != 80 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mproject_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLayer_6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_directions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLayer_6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 15\u001b[0m, in \u001b[0;36mproject_activations\u001b[0;34m(activations, detector_direction)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(activations\u001b[38;5;241m.\u001b[39mshape, detector_direction\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Project each activation onto the normalized detector direction\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m projection \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_direction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m projection\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (40,40,768) and (80,768) not aligned: 768 (dim 2) != 80 (dim 0)"
     ]
    }
   ],
   "source": [
    "project_activations(test_activations['Layer_6'], activation_directions['Layer_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1018, -1.4912, -1.8084,  ..., -1.1475, -0.9938,  0.6507],\n",
      "         [-5.1746, -1.2403,  4.2255,  ...,  4.1594, -4.9427,  4.5651],\n",
      "         [-2.2485,  0.1615, -1.8502,  ...,  0.6150, -0.9088,  1.7466],\n",
      "         ...,\n",
      "         [-5.1746, -1.2403,  4.2255,  ...,  4.1594, -4.9427,  4.5651],\n",
      "         [-5.1746, -1.2403,  4.2255,  ...,  4.1594, -4.9427,  4.5651],\n",
      "         [-4.1792, -2.1417, -2.7534,  ...,  2.2946, -1.1521,  0.8790]],\n",
      "\n",
      "        [[-1.0778, -0.7887,  0.4466,  ...,  0.7183,  0.2962, -1.2071],\n",
      "         [ 0.1360, -0.7399, -2.8891,  ..., -1.7986, -1.4220,  1.0074],\n",
      "         [-1.0963, -0.7834,  0.4204,  ...,  0.7153,  0.2911, -1.2054],\n",
      "         ...,\n",
      "         [ 0.1360, -0.7399, -2.8891,  ..., -1.7986, -1.4220,  1.0074],\n",
      "         [ 0.1360, -0.7399, -2.8891,  ..., -1.7986, -1.4220,  1.0074],\n",
      "         [-0.6949, -0.1579, -3.3876,  ..., -0.7588, -1.7090,  2.7816]],\n",
      "\n",
      "        [[-1.1604, -0.6778,  0.5964,  ...,  0.4474,  0.4029, -0.5293],\n",
      "         [-0.9136,  1.0094, -3.9301,  ..., -0.5923, -1.2824,  2.1706],\n",
      "         [-0.5200, -0.4989, -1.6373,  ..., -1.7636, -0.3942,  1.4308],\n",
      "         ...,\n",
      "         [-0.9136,  1.0094, -3.9301,  ..., -0.5923, -1.2824,  2.1706],\n",
      "         [-0.9136,  1.0094, -3.9301,  ..., -0.5923, -1.2824,  2.1706],\n",
      "         [-3.4746,  1.1061, -2.0982,  ..., -3.6422, -4.5273,  0.1375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7235, -0.6430,  1.0195,  ...,  1.0359,  0.7361, -0.9556],\n",
      "         [-0.8328, -1.1493, -0.4980,  ..., -2.0161,  0.1651,  1.0963],\n",
      "         [-0.7255, -0.6390,  0.9878,  ...,  1.0437,  0.7455, -0.9212],\n",
      "         ...,\n",
      "         [-0.8328, -1.1493, -0.4980,  ..., -2.0161,  0.1651,  1.0963],\n",
      "         [-0.8328, -1.1493, -0.4980,  ..., -2.0161,  0.1651,  1.0963],\n",
      "         [-2.1913,  6.6851, -4.2015,  ...,  1.4570, -0.5473, -0.7877]],\n",
      "\n",
      "        [[-0.1923, -0.4244,  1.1899,  ...,  0.7340,  0.4848, -0.9650],\n",
      "         [-0.8504, -1.7691, -0.7297,  ..., -2.8609, -0.1717,  0.9814],\n",
      "         [-0.2077, -0.3939,  1.1656,  ...,  0.7467,  0.4909, -0.9283],\n",
      "         ...,\n",
      "         [-0.8504, -1.7691, -0.7297,  ..., -2.8609, -0.1717,  0.9814],\n",
      "         [-0.8504, -1.7691, -0.7297,  ..., -2.8609, -0.1717,  0.9814],\n",
      "         [-2.7812, -1.3574, -0.4382,  ..., -0.7344,  2.1286,  0.9516]],\n",
      "\n",
      "        [[-0.8983, -0.6383,  0.5750,  ...,  0.1706,  0.4495, -0.9697],\n",
      "         [-0.9185, -0.6273,  0.5355,  ...,  0.1895,  0.4627, -0.8986],\n",
      "         [-0.9047, -0.6354,  0.5624,  ...,  0.1959,  0.4535, -0.9346],\n",
      "         ...,\n",
      "         [-0.9185, -0.6273,  0.5355,  ...,  0.1895,  0.4627, -0.8986],\n",
      "         [-0.9185, -0.6273,  0.5355,  ...,  0.1895,  0.4627, -0.8986],\n",
      "         [-0.0508, -2.6947, -1.5013,  ..., -1.0446, -0.4692,  1.3855]]])\n"
     ]
    }
   ],
   "source": [
    "print(test_activations['Layer_6'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
