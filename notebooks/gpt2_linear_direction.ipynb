{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to use contrasting pairs of animal/non-animal related sentences to identify an \"animal direction\" in any of the layers in the residual stream of the last tokens of the sentences in GPT2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/anaconda3/envs/acd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def get_last_token_activations(sentences, model, tokenizer, device='cpu'):\n",
    "    # Ensure the model and data are on the correct device\n",
    "    model.to(device)\n",
    "    \n",
    "    activations = {}\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output[0].detach()\n",
    "        return hook\n",
    "\n",
    "    # Register hooks to each layer of the model to capture activations\n",
    "    hooks = [layer.register_forward_hook(get_activation(f'Layer_{i}')) for i, layer in enumerate(model.transformer.h)]\n",
    "\n",
    "    # Tokenize and encode the sentences, then send to specified device\n",
    "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    # Perform model forward pass and prevent gradient computations\n",
    "    with t.no_grad():\n",
    "        model(**inputs)\n",
    "    \n",
    "    # Compute the index of the last non-padded token for each sentence\n",
    "    last_token_indices = (inputs['attention_mask'].sum(dim=1) - 1).tolist()\n",
    "    \n",
    "    # Use advanced indexing to select the last token for each sentence in each layer\n",
    "    last_token_activations = {}\n",
    "    for key, val in activations.items():\n",
    "        # Create a tensor of batch indices\n",
    "        batch_indices = t.arange(val.size(0), device=device)\n",
    "        # Index into the output for the last token of each sentence\n",
    "        last_token_activations[key] = val[batch_indices, last_token_indices, :]\n",
    "    \n",
    "    # Clean up hooks after use to prevent memory leaks\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    return last_token_activations\n",
    "\n",
    "def compute_animal_directions(animal_sentences, non_animal_sentences, model, layer_names, tokenizer, device='cpu'):\n",
    "    \"\"\"\n",
    "    Computes the direction vector (difference in means of activations) for animal vs. non-animal sentences\n",
    "    across specified layers in a given model.\n",
    "\n",
    "    Parameters:\n",
    "    - animal_sentences (list of str): Sentences classified as 'animal'.\n",
    "    - non_animal_sentences (list of str): Sentences classified as 'non-animal'.\n",
    "    - model (torch.nn.Module): Model to compute activations from.\n",
    "    - tokenizer (Tokenizer): Tokenizer that is compatible with the model.\n",
    "    - device (str): Device to perform computations on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with layer names as keys and direction vectors as values.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    animal_activations = get_last_token_activations(animal_sentences, model, tokenizer)\n",
    "\n",
    "    non_animal_activations = get_last_token_activations(non_animal_sentences, model, tokenizer)\n",
    "\n",
    "\n",
    "    animal_directions = {}\n",
    "\n",
    "    for layer_name in layer_names:\n",
    "        animal_layer_activations = animal_activations[layer_name].cpu().numpy()\n",
    "        non_animal_layer_activations = non_animal_activations[layer_name].cpu().numpy()\n",
    "\n",
    "        print(animal_layer_activations.shape)\n",
    "        animal_directions[layer_name] = np.mean(animal_layer_activations, axis=0) - np.mean(non_animal_layer_activations, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return animal_directions\n",
    "\n",
    "def project_activations(activations, detector_direction):\n",
    "    \"\"\"\n",
    "    Project activation vectors onto the detector direction.\n",
    "    \n",
    "    Parameters:\n",
    "    - activations (numpy.ndarray): Activation vectors to project.\n",
    "    - detector_direction (numpy.ndarray): The detector direction vector.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: Scalar values of the projection of each activation onto the detector direction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Project each activation onto the normalized detector direction\n",
    "    projection = np.dot(activations, detector_direction)\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Label           Sentence\n",
      "0  Animal       I like cats.\n",
      "1  Animal       I like dogs.\n",
      "2  Animal  I like elephants.\n",
      "3  Animal     I like tigers.\n",
      "4  Animal      I like birds.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file to verify it\n",
    "df_sentences = pd.read_csv('../datasets/ilikecats.csv')\n",
    "\n",
    "# Display the first few entries\n",
    "print(df_sentences.head())\n",
    "\n",
    "# Filter the DataFrame for rows where the Label column is 'Animal'\n",
    "animal_sentences = df_sentences[df_sentences['Label'] == 'Animal']['Sentence'].tolist()\n",
    "non_animal_sentences = df_sentences[df_sentences['Label'] == 'Non-Animal']['Sentence'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model #huggingface-cli login\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "# Set the EOS token as the padding token if it's not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers = 12\n",
      "Number of tokens = 10\n"
     ]
    }
   ],
   "source": [
    "# Print max number of layers and max number of tokens\n",
    "print(f\"Number of layers = {len(model.transformer.h)}\")\n",
    "max_tokens = tokenizer(df_sentences['Sentence'].tolist(), return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].shape[-1]\n",
    "print(f\"Number of tokens = {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 768)\n"
     ]
    }
   ],
   "source": [
    "# Compute animal direction for each layer\n",
    "layer_names = [f'Layer_{i}' for i in range(6,7)] # Max is range(len(model.transformer.h)\n",
    "\n",
    "\n",
    "# Shorten samples, create train-test split, Shuffle sentences\n",
    "\n",
    "num_examples = 300\n",
    "animal_sentences_short = animal_sentences[0:num_examples]\n",
    "non_animal_sentences_short = non_animal_sentences[0:num_examples]\n",
    "\n",
    "train_test_split = 0.8\n",
    "\n",
    "train_animal_sentences = animal_sentences_short[0:int(num_examples*0.8)]\n",
    "test_animal_sentences = animal_sentences_short[int(num_examples*0.8):]\n",
    "\n",
    "train_non_animal_sentences = non_animal_sentences_short[0:int(num_examples*0.8)]\n",
    "test_non_animal_sentences = non_animal_sentences_short[int(num_examples*0.8):]\n",
    "\n",
    "\n",
    "random.shuffle(animal_sentences_short)\n",
    "random.shuffle(non_animal_sentences_short)\n",
    "\n",
    "activation_directions = compute_animal_directions(train_animal_sentences, train_non_animal_sentences, model, layer_names, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_animal_sentences + test_non_animal_sentences\n",
    "labels = [1]*len(test_animal_sentences) + [0]*len(test_non_animal_sentences)\n",
    "test_activations = get_last_token_activations(test_data, model, tokenizer, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = project_activations(test_activations['Layer_6'], activation_directions['Layer_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(values, labels):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of classification where positive numbers in 'values'\n",
    "    should correspond to 1s in 'labels' and negative numbers to 0s.\n",
    "\n",
    "    Parameters:\n",
    "    - values (list of float): List of numerical values.\n",
    "    - labels (list of int): Corresponding list of binary labels (1s and 0s).\n",
    "\n",
    "    Returns:\n",
    "    - float: The accuracy of the match-up, represented as a fraction between 0 and 1.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    total_count = len(values)\n",
    "\n",
    "    for value, label in zip(values, labels):\n",
    "        # Predict 1 if value is positive, 0 if negative\n",
    "        predicted_label = 1 if value > 0 else 0\n",
    "        # Check if prediction matches the label\n",
    "        if predicted_label == label:\n",
    "            correct_count += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / total_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(results, labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
