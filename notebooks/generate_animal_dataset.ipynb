{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to generate a dataset that consists of animal and non-animal sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sentences for a topic\n",
    "def generate_sentences(topic, num_sentences_per_topic, model, client):\n",
    "    instruction_text = f\"Your task is to generate {num_sentences_per_topic} sentences related to the topic '{topic}'. Each sentence should be unique and vary in format. Include factual descriptions, personal anecdotes, direct dialogue, and narrative elements. Ensure each sentence captures different aspects of {topic}, ranging from scientific facts to human interactions or experiences with {topic}. The more variety, the better! Aim for a mix of informative, engaging, and thought-provoking content to provide a rich, multi-dimensional perspective. Regarding the formatting of your response, only respond with the sentences one after the other, separated by newlines. Nothing extra. No bullet points or numbers or unnecssary whitespace.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": instruction_text},\n",
    "                {\"role\": \"user\", \"content\": ''}\n",
    "            ]\n",
    "        )\n",
    "    return response.choices[0].message.content.split('\\n')\n",
    "\n",
    "\n",
    "def format_sentence(sentence):\n",
    "    # Strip any leading/trailing whitespace\n",
    "    sentence = sentence.strip()\n",
    "    # Correct any misplaced punctuation around speech marks\n",
    "    sentence = re.sub(r'[\"\\']\\s*[.,!?]*\\s*$', '\"', sentence)\n",
    "    # Check if the sentence is empty or lacks meaningful content after stripping\n",
    "    if not sentence or not re.search(r'\\w', sentence):\n",
    "        return None\n",
    "    # Ensure the sentence ends with proper punctuation before any closing speech mark\n",
    "    if not re.search(r'[.!?][\"\\']?$', sentence):\n",
    "        sentence += '.'\n",
    "    # Capitalize the first letter of the sentence\n",
    "    sentence = sentence[0].upper() + sentence[1:]\n",
    "    return sentence\n",
    "\n",
    "def format_sentence_list(sentence_list):\n",
    "    # Use a list comprehension to format sentences and exclude None entries\n",
    "    return [formatted for sentence in sentence_list if (formatted := format_sentence(sentence)) is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of animal topics generated by GPT 4\n",
    "animal_topics = [\n",
    "    'tropical birds', 'mountain mammals', 'deep sea fish', 'desert reptiles', 'polar bears', 'forest amphibians',\n",
    "    'grassland herbivores', 'savannah carnivores', 'freshwater crustaceans', 'coral reef organisms', 'nocturnal birds',\n",
    "    'daytime predators', 'wetland insects', 'cave-dwelling animals', 'volcanic area natives', 'arctic fish',\n",
    "    'coastal wildlife', 'suburban animals', 'urban birds', 'rural farm animals', 'temperate forest creatures',\n",
    "    'coniferous forest dwellers', 'deciduous forest inhabitants', 'rainforest canopy wildlife', 'mangrove forest species',\n",
    "    'peat bog animals', 'steppes wildlife', 'taiga biome animals', 'tundra wildlife', 'riverbank animals', 'lake dwellers',\n",
    "    'swamp creatures', 'jungle animals', 'plateau wildlife', 'plain grazers', 'hill fauna', 'sand dune species',\n",
    "    'marsh occupants', 'prairie dogs', 'estuary life forms', 'delta region animals', 'mountain goats', 'volcanic island birds',\n",
    "    'cliff nesting birds', 'deep forest animals', 'shrubland insects', 'moorland birds', 'heathland animals',\n",
    "    'chaparral wildlife', 'feral animals', 'domesticated animals', 'solitary animals', 'social animals', 'migratory species',\n",
    "    'sedentary animals', 'ground-nesting birds', 'tree-dwelling mammals', 'burrowing animals', 'arboreal reptiles',\n",
    "    'amphibious fish', 'saltwater fish', 'coldwater fish', 'warmwater fish', 'invasive species', 'endangered species',\n",
    "    'protected species', 'hunted animals', 'poached animals', 'rescued animals', 'rehabilitated animals', 'released animals',\n",
    "    'monitored species', 'tagged animals', 'photographed wildlife', 'studied species', 'well-known animals', 'rare animals',\n",
    "    'common animals', 'keystone species', 'indicator species', 'pioneer species', 'native species', 'exotic species',\n",
    "    'hybrid species', 'genetically modified animals', 'lab animals', 'zoo animals', 'safari park animals', 'pet animals',\n",
    "    'working animals', 'performance animals', 'show animals', 'race animals', 'breeding animals', 'nesting birds',\n",
    "    'hatching reptiles', 'spawning fish', 'moulting crustaceans', 'hibernating animals', 'estivating animals'\n",
    "]\n",
    "\n",
    "# List of non-animal topics generated by GPT 4\n",
    "non_animal_topics = [\n",
    "    'urban infrastructure', 'rural life', 'public parks', 'gardening tips', 'home decorating', 'culinary arts',\n",
    "    'popular recipes', 'coffee culture', 'tea varieties', 'craft beers', 'wine regions', 'baking techniques',\n",
    "    'festival celebrations', 'wedding traditions', 'dance styles', 'musical instruments', 'theater productions',\n",
    "    'film genres', 'television series', 'comic books', 'graphic novels', \"children's books\", 'science fiction themes',\n",
    "    'fantasy worlds', 'mystery plots', 'historical events', 'modern warfare', 'peace movements', 'political campaigns',\n",
    "    'civil rights movements', 'non-profit organizations', 'global charities', 'environmental issues', 'climate change effects',\n",
    "    'recycling methods', 'waste management', 'water conservation', 'renewable resources', 'solar power innovations',\n",
    "    'wind energy', 'hydroelectric systems', 'smart homes', 'wearable technology', 'mobile applications',\n",
    "    'gaming consoles', 'board games', 'puzzle solving', 'DIY projects', 'woodworking', 'metalworking', 'sewing crafts',\n",
    "    'knitting patterns', 'pottery techniques', 'photography styles', 'digital art', 'street art', 'pop music evolution',\n",
    "    'jazz history', 'classical composers', 'rock music icons', 'hip-hop culture', 'electronic dance music',\n",
    "    'fashion trends', 'hairstyling tips', 'makeup tutorials', 'skincare routines', 'fitness regimes', 'yoga practices',\n",
    "    'martial arts', 'team sports', 'extreme sports', 'outdoor adventures', 'camping essentials', 'hiking trails',\n",
    "    'travel destinations', 'cultural landmarks', 'academic research', 'quantum computing', 'artificial intelligence',\n",
    "    'neural networks', 'econometrics', 'behavioral psychology', 'public health studies', 'urban planning',\n",
    "    'international relations', 'space physics', 'geographic information systems', 'biomedical engineering',\n",
    "    'sustainability science', 'robotics technology', '3D printing technology', 'cryptographic systems',\n",
    "    'virtual reality developments', 'augmented reality trends', 'astronomy', 'public health', 'urban design', \n",
    "    'world literature', 'sustainable farming', 'digital marketing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal topic number: 0\n",
      "Non-animal topic number: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Define the animal dataset\n",
    "animal_dataset = []\n",
    "\n",
    "# Define the non-animal dataset\n",
    "non_animal_dataset = []\n",
    "\n",
    "# Define the number of sentences per topic\n",
    "num_sentences_per_topic = 10\n",
    "\n",
    "# Define the maximum allowable difference in the number of sentences\n",
    "max_error = 2\n",
    "\n",
    "# Define the GPT model\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Choose list of animal and non-animal topics\n",
    "num_topics = 100\n",
    "animal_topics = animal_topics[0:num_topics]\n",
    "non_animal_topics = non_animal_topics[0:num_topics]\n",
    "\n",
    "# Generate animal sentence dataset by generating sentences related to animal topics\n",
    "for i, topic in enumerate(animal_topics):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Animal topic number: {i}\")\n",
    "    while True:\n",
    "        try:\n",
    "            sentences_list = generate_sentences(topic, num_sentences_per_topic, model, client)\n",
    "            if abs(len(sentences_list) - num_sentences_per_topic) <= max_error:\n",
    "                animal_dataset += sentences_list\n",
    "                break  # Exit the retry loop if within acceptable error range\n",
    "            else:\n",
    "                raise ValueError(\"Number of generated sentences is outside the acceptable error range.\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error generating sentences for '{topic}': {e}\")\n",
    "\n",
    "# Generate non-animal sentence dataset by generating sentences related to non-animal topics\n",
    "for i, topic in enumerate(non_animal_topics):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Non-animal topic number: {i}\")\n",
    "    while True:\n",
    "        try:\n",
    "            sentences_list = generate_sentences(topic, num_sentences_per_topic, model, client)\n",
    "            if abs(len(sentences_list) - num_sentences_per_topic) <= max_error:\n",
    "                non_animal_dataset += sentences_list\n",
    "                break  # Exit the retry loop if within acceptable error range\n",
    "            else:\n",
    "                raise ValueError(\"Number of generated sentences is outside the acceptable error range.\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error generating sentences for '{topic}': {e}\")\n",
    "\n",
    "# Do post-processing to get rid of empty sentences, whitespace, etc.\n",
    "animal_dataset = format_sentence_list(animal_dataset)\n",
    "non_animal_dataset = format_sentence_list(non_animal_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "\n",
    "# Writing JSON data\n",
    "with open('../datasets/non_animal_1000_gpt35.json', 'w') as f:\n",
    "    json.dump(non_animal_dataset, f, indent=4)\n",
    "\n",
    "with open('../datasets/animal_1000_gpt35.json', 'w') as f:\n",
    "    json.dump(animal_dataset, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
