{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to generate the hidden cognition dataset with animal appended facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/anaconda3/envs/acd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import openai\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import accelerate\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple topics generated by GPT 4 (chat)\n",
    "non_animal_topics = [\n",
    "    \"rivers\", \"mountains\", \"cities\", \"countries\", \"oceans\", \"landmarks\",\n",
    "    \"plants\", \"fruits\", \"vegetables\", \"weather\", \"seasons\",\n",
    "    \"sports\", \"games\", \"colors\", \"shapes\", \"numbers\", \"letters\",\n",
    "    \"school subjects\", \"jobs\", \"tools\", \"kitchen items\", \"household appliances\", \"furniture\",\n",
    "    \"clothing\", \"footwear\", \"holidays\", \"festivals\", \"movies\", \"books\",\n",
    "    \"music instruments\", \"songs\", \"bands\", \"paintings\", \"artists\",\n",
    "    \"materials\", \"metals\", \"stones\", \"trees\", \"flowers\",\n",
    "    \"transportation\", \"cars\", \"bicycles\", \"airplanes\", \"ships\",\n",
    "    \"space\", \"planets\", \"stars\", \"moon phases\", \"solar system\",\n",
    "    \"toys\", \"video games\", \"board games\", \"card games\", \"puzzles\",\n",
    "    \"exercise\", \"dances\", \"martial arts\", \"olympic sports\", \"water sports\",\n",
    "    \"winter sports\", \"team sports\", \"individual sports\", \"outdoor activities\", \"camping\",\n",
    "    \"breakfast foods\", \"lunch foods\", \"dinner foods\", \"snacks\", \"desserts\",\n",
    "    \"beverages\", \"cooking methods\", \"kitchen tools\", \"baking items\", \"spices\",\n",
    "    \"family members\", \"emotions\", \"body parts\", \"senses\",\n",
    "    \"time units\", \"directions\", \"positions\", \"speed units\", \"measurements\",\n",
    "    \"toys\", \"babies\", \"shapes\", \"numbers\", \"letters\", \"dinosaurs\",\n",
    "    \"cartoons\", \"superheroes\", \"fairy tales\", \"ice cream flavors\", \"parks\",\n",
    "    \"candy types\", \"school supplies\", \"puzzles\", \"board games\", \"playgrounds\", \"birthday parties\"\n",
    "]\n",
    "\n",
    "\n",
    "animal_topics = [\"birds\", \"fish\", \"insects\", \"mammals\", \"reptiles\", \"pets\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['What does a thermometer measure?', 'Which country is famous for the Maasai tribe?', 'How do plants reproduce?', 'What is the significance of Mount Everest to climbers?', 'In which city is the famous Colosseum located?']\n"
     ]
    }
   ],
   "source": [
    "def validate_questions(questions):\n",
    "    valid_questions = []\n",
    "    for question in questions:\n",
    "        question = question.strip()\n",
    "        if question.endswith('?'):\n",
    "            valid_questions.append(question)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid question format: {question}\")\n",
    "    return valid_questions\n",
    "\n",
    "# Example usage within your main code block, with exception handling\n",
    "client = openai.OpenAI()\n",
    "\n",
    "topics =  non_animal_topics[0:10]# assuming topics is predefined\n",
    "num_questions = 10  # Define how many questions you expect per topic\n",
    "error_tolerance = 2  # Acceptable margin of error in the number of questions\n",
    "\n",
    "\n",
    "instruction_text = (f\"Hi, your task is to generate a list of {num_questions} simple questions related to the topic the user specifies. \"\n",
    "          \"Each question should be simple, short (one sentence), and each sentence should be separated by two vertical bars: ||. \"\n",
    "          \"For example, if the topic is 'countries' and you've been asked to give 2 questions, your response could be: \"\n",
    "          \"'What is the capital of Japan? || What is the largest country in the world?'\")\n",
    "\n",
    "questions = []\n",
    "\n",
    "for topic in topics:\n",
    "    attempts = 0\n",
    "    max_attempts = 3  # Define max attempts in case of repeated failures\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": instruction_text},\n",
    "                    {\"role\": \"user\", \"content\": topic}\n",
    "                ]\n",
    "            )\n",
    "            topic_questions = response.choices[0].message.content.split('|| ')\n",
    "            valid_topic_questions = validate_questions(topic_questions)  # This might raise an exception\n",
    "            if not (num_questions - error_tolerance <= len(valid_topic_questions) <= num_questions + error_tolerance):\n",
    "                raise ValueError(f\"Number of questions generated is {len(valid_topic_questions)}! Number of questions should be around {num_questions}.\")\n",
    "            questions.extend(valid_topic_questions)\n",
    "            break  # Break out of the while loop on success\n",
    "        except ValueError as e:\n",
    "            print(e)  # Handle the specific error raised in validate_questions\n",
    "            break  # Optional: Decide if you want to break or retry\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            attempts += 1\n",
    "            if attempts >= max_attempts:\n",
    "                print(f\"Failed to generate questions for topic '{topic}' after {max_attempts} attempts.\")\n",
    "\n",
    "print(len(questions))\n",
    "random.shuffle(questions)\n",
    "print(questions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON data\n",
    "with open('../datasets/animal_hc_raw.json', 'w') as f:\n",
    "    json.dump(questions, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load datasets\n",
    "# with open('../datasets/hc_animal_616_gpt_3_5.json', 'r') as file:\n",
    "#     animal_dataset = json.load(file)\n",
    "\n",
    "# with open('../datasets/hc_non_animal_616_gpt_3_5.json', 'r') as file:\n",
    "#     non_animal_dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create lists for data and labels\n",
    "# sentences = animal_sentences_llama + non_animal_sentences_llama\n",
    "# labels = ['Animal'] * len(animal_sentences_llama) + ['Non-Animal'] * len(non_animal_sentences_llama)\n",
    "\n",
    "# # Create a DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'Label': labels,\n",
    "#     'Sentence': sentences\n",
    "# })\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df.to_csv('../datasets/hc_dataset_llama.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check dataset\n",
    "# df = pd.read_csv('../datasets/hc_dataset_llama.csv')\n",
    "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
